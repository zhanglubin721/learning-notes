# 存储原理

## String类型存储结构

我们都知道，`Redis`是由`C`语言编写的。在`C`语言中，字符串标准形式是以空字符`\0`作为结束符的，但是`Redis`里面的字符串却没有直接沿用`C`语言的字符串。主要是因为`C`语言中获取字符串长度可以调用`strlen`这个标准函数，这个函数的时间复杂度是`O(N)`，由于`Redis`是单线程的，承受不了这个时间复杂度。

Redis中string的存储方式

`Redis`的`RedisObject`的数据结构，如下所示：

```c
typedef struct redisObject {
    // 对外的类型 string list set hash zset等 4bit
    unsigned type:4;
    // 底层存储方式 4bit
    unsigned encoding:4;
    // LRU 时间 24bit
    unsigned lru:LRU_BITS; 
    // 引用计数  4byte
    int refcount;
    // 指向对象的指针  8byte
    void *ptr;
} robj;
```

对于不同的对象，`Redis`会使用不同的类型来存储。对于同一种类型`type`会有不同的存储形式`encoding`。对于`string`类型的字符串，其底层编码方式共有三种，分别为`int`、`embstr`和`raw`。

- `int`：当存储的字符串全是数字时，此时使用`int`方式来存储；
- `embstr`：当存储的字符串长度小于44个字符时，此时使用`embstr`方式来存储；
- `raw`：当存储的字符串长度大于44个字符时，此时使用`raw`方式来存储；

使用`object encoding key`可以查看`key`对应的`encoding`类型，如下所示：

[![img](image/1593641-20200721004859188-1339712134.png)](https://img2020.cnblogs.com/blog/1593641/202007/1593641-20200721004859188-1339712134.png)

对于`embstr`和`raw`这两种`encoding`类型，其存储方式还不太一样。对于`embstr`类型，它将`RedisObject`对象头和`SDS`对象在内存中地址是连在一起的，但对于`raw`类型，二者在内存地址不是连续的。

[![img](image/1593641-20200721004914922-1956927112.png)](https://img2020.cnblogs.com/blog/1593641/202007/1593641-20200721004914922-1956927112.png)

### SDS

在介绍`string`类型的存储类型时，我们说到，对于`embstr`和`raw`两种类型其存储方式不一样，但`ptr`指针最后都指向一个`SDS`的结构。那什么是`SDS`呢？`Redis`中的字符串称之为`Simple Dynamic String`，简称为`SDS`。与普通`C`语言的原始字符串结构相比，`sds`多了一个`sdshdr`的头部信息，`sdshdr`基本数据结构如下所示：

```c
struct sdsshr<T>{
    T len;//数组长度
    T alloc;//数组容量
    unsigned  flags;//sdshdr类型
    char buf[];//数组内容
}
```

可以看出，`SDS`的结构有点类似于`Java`中的`ArrayList`。`buf[]`表示真正存储的字符串内容，`alloc`表示所分配的数组的长度，`len`表示字符串的实际长度，并且由于`len`这个属性的存在，`Redis`可以在`O(1)`的时间复杂度内获取数组长度。

为了追求对于内存的极致优化，对于不同长度的字符串，`Redis`底层会采用不同的结构体来表示。在`Redis`中的`sds.h`源码中存在着五种`sdshdr`，分别如下：

```c
struct __attribute__ ((__packed__)) sdshdr5 {
    unsigned char flags; /* 3 lsb of type, and 5 msb of string length */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr8 {
    uint8_t len; /* used */
    uint8_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr16 {
    uint16_t len; /* used */
    uint16_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr32 {
    uint32_t len; /* used */
    uint32_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr64 {
    uint64_t len; /* used */
    uint64_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
```

上面说了，`Redis`底层会根据字符串的长度来决定具体使用哪种类型的`sdshdr`。可以看出，`sdshdr5`明显区别于其他四种结构，它一般只用于存储长度不会变化，且长度小于32个字符的字符串。但现在一般都不再使用该结构，**因为其结构没有`len`和`alloc`这两个属性,不具备动态扩容操作**，一旦预分配的内存空间使用完，就需要重新分配内存并完成数据的复制和迁移，类似于`ArrayList`的扩容操作，这种操作对性能的影响很大。

上面介绍`sdshdr`属性的时候说过，`flag`这个属性用于标识使用哪种`sdshdr`类型，`flag`的低三位标识当前`sds`的类型，分别如下所示：

```c
#define SDS_TYPE_5  0
#define SDS_TYPE_8  1
#define SDS_TYPE_16 2
#define SDS_TYPE_32 3
#define SDS_TYPE_64 4
```

同时，注意到在每个`sdshdr`的头定义上都有一个`attribute((packed))`，这个是为了告诉`gcc`**取消优化对齐**，这样，每个字段分配的内存地址就是**紧紧排列在一起的**，`Redis`中字符串参数的传递直接使用`char*`指针，其实现原理在于，由于`sdshdr`内存分配禁止了优化对齐，所以`sds[-1]`指向的就是`flags`属性的内存地址，而通过`flags`属性又可以确定`sdshdr`的属性，进而可以读取头部字段确定`sds`的相关属性。

sds的逻辑图如下所示：

[![img](image/1593641-20200721004934563-296979682.png)](https://img2020.cnblogs.com/blog/1593641/202007/1593641-20200721004934563-296979682.png)

**sdshdr的优势**

相比较于`C`语言原始的字符串，`sdshdr`的具备一些优势。

**长度获取**

由于`sdshdr`中存在`len`这个属性，所以可以在`O(1)`的时间复杂度下获得长度；而传统的`C`语言得使用`strlen`这个标准函数获取，时间复杂度为`O(N)`。

**避免频繁的内存分配**

原始的`C`语言一直使用与长度匹配的内存，这样在追加字符串导致字符串长度发生变化时，就必须进行内存的重新分配。内存重新分配涉及到复杂算法和系统调用，耗费性能和时间。对于`Redis`来说，它是单线程的，如果使用原始的字符串结构，势必会引发频繁的内存重分配，这个显然是不合理的。

因而，`sds`每次进行内存分配时，都会通过内存的预分配来减少因为修改字符串而引发的内存重分配次数。这个原理可以参数`Java`中的`ArrayList`，一般在使用`ArrayList`时都会建议使用带有容量的构造方式，这样可以避免频繁`resize`。

对于`SDS`来说，当其使用`append`进行字符串追加时，程序会用 **alloc-len 比较下剩下的空余内存是否足够分配追加的内容**，如果不够自然触发内存重分配，而如果剩余未使用内存空间足够放下，那么将直接进行分配，无需内存重分配。其扩容策略为，**当字符串占用大小小于1M时，每次分配为`len` \* 2，也就是保留100%的冗余；大于1M后，为了避免浪费，只多分配1M的空间。**

通过这种预分配策略， SDS 将连续增长 N 次字符串所需的内存重分配次数**从必定 N 次降低为最多 N 次。**

**缓冲区溢出**

**缓冲区溢出是指当某个数据超过了处理程序限制的范围时，程序出现的异常操作。**原始的`C`语言中，是由编码者自己来分配字符串的内存，当出现内存分配不足时就会发生**缓存区溢出**。而`sds`的修改函数在修改前会判断内存，动态的分配内存，杜绝了**缓冲区溢出**的可能性。

**二进制安全**

对于原始的`C`语言字符串来说，它会通过判断当前字符串中是否存在空字符`\0`来确定是否已经是字符串的结尾。因而在某些情况下，如使用空格进行分割一段字符串时，或者是图片或者视频等二进制文件中存在`\0`等，就会出问题。而`sds`不是通过空字符串来判断字符串是否已经到结尾，而是通过`len`这个字段的值。所以说，`sds`还具备**二进制安全**这个特性，即可以安全的存储具有特殊格式的二进制数据。

**总结**

[![img](image/1593641-20200831194045515-1907392740.png)](https://img2020.cnblogs.com/blog/1593641/202008/1593641-20200831194045515-1907392740.png)

## List类型存储结构

Redis列表list 底层原理
![在这里插入图片描述](image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzg2MjgyNA==,size_16,color_FFFFFF,t_70.png)

在版本3.2之前，Redis 列表list使用两种[数据结构](https://so.csdn.net/so/search?q=数据结构&spm=1001.2101.3001.7020)作为底层实现：

> 1. 压缩列表ziplist
> 2. 双向链表linkedlist

因为[双向链表](https://so.csdn.net/so/search?q=双向链表&spm=1001.2101.3001.7020)占用的内存比压缩列表要多， 所以当创建新的列表键时， 列表会优先考虑使用压缩列表， 并且在有需要的时候， 才从压缩列表实现转换到双向链表实现。

**压缩列表转化成双向链表**
创建新列表时 redis 默认使用 redis_encoding_ziplist 编码， 当以下任意一个条件被满足时， 列表会被转换成redis_encoding_linkedlist 编码：

> 1. 单字符串的值长度超过 server.list_max_ziplist_value （默认值为 64 ）。
> 2. ziplist 包含的节点超过 server.list_max_ziplist_entries （默认值为 512 ）。

注意：这两个条件是可以修改的，在 redis.conf 中：

```bash
list-max-ziplist-value 64 
list-max-ziplist-entries 512 
```

### 压缩列表ziplist

压缩列表 ziplist 是为 Redis 节约内存而开发的。

> 1. ziplist 是由一系列特殊编码的内存块构成的列表(像内存连续的数组，但每个元素长度不同)， 一个 ziplist
>    可以包含多个节点（entry）。
> 2. ziplist 将表中每一项存放在前后连续的地址空间内，每一项因占用的空间不同，而采用变长编码。

由于内存是连续分配的，所以遍历速度很快。在3.2之后，ziplist被quicklist替代。但是仍然是zset底层实现之一。

**ziplist 是一个特殊的双向链表**
特殊之处在于：没有维护双向指针:prev next；而是存储**上一个 entry的长度**和**当前entry的长度**，通过长度推算下一个元素在什么地方。牺牲读取的性能，获得高效的存储空间，因为(简短字符串的情况)存储指针比存储entry长度 更费内存。这是典型的"时间换空间"。

压缩列表ziplist存储结构
ziplist使用连续的内存块，每一个节点（entry）都是连续存储的；ziplist 存储分布如下：

```
area        |<---- ziplist header ---->|<----------- entries ------------->|<-end->|

size          4 bytes  4 bytes  2 bytes    ?        ?        ?        ?     1 byte
            +---------+--------+-------+--------+--------+--------+--------+-------+
component   | zlbytes | zltail | zllen | entry1 | entry2 |  ...   | entryN | zlend |
            +---------+--------+-------+--------+--------+--------+--------+-------+
                                       ^                          ^        ^
address                                |                          |        |
                                ZIPLIST_ENTRY_HEAD                |   ZIPLIST_ENTRY_END
                                                                  |
                                                         ZIPLIST_ENTRY_TAIL
```

第一行：整个数据结构是header-entries-end
第二行：component行每个小空间最占用的字节数。
第三行：对ziplist每块空间更细的划分

图中各个域的含义如下：
![在这里插入图片描述](image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzg2MjgyNA==,size_16,color_FFFFFF,t_70-20220413112812089.png)

其中entries才是ziplist真正存储节点的区域，每一项都连续存储的，构成entry1、entry2、….entryN。
由于每一项、占用的空间可能都不同，只能在添加entry的时候确定，也就是每个entry占用的实际长度只有在节点添加后才确定，因此**entry采用变长编码**。

ziplist节点entry结构
每一个存储节点（entry）都是一个zlentry (zip list entry)。

![在这里插入图片描述](image/20210518233838627.png)

ziplist每一个存储节点、都是一个 zlentry，就是上文我们所说的entry；
zlentry的源码定义：

```c
typedef struct zlentry {         // 压缩列表节点
    unsigned int prevrawlensize; //prevrawlensize是指prevrawlen的大小，有1字节和5字节两种
    unsigned int prevrawlen;     //prevrawlen是前一个节点的长度
    unsigned int lensize, 		 //lensize为编码len所需的字节大小
    unsigned int len;   		 // len为当前节点长度 
    unsigned int headersize;     // 当前节点的header大小
    unsigned char encoding;      // 节点的编码方式
    unsigned char *p;            // 指向节点的指针
} zlentry;
```

每一个存储节点 zlentry，都包含

> 1. prevrawlen 前一个 entry的长度
> 2. lensize 当前entry的长度

**作用：当前节点的指针 e 减去前一个entry的长度，得出的结果就是指向前一个节点的地址p**

```c
void zipEntry(unsigned char *p, zlentry *e) {   // 根据节点指针返回一个enrty
    ZIP_DECODE_PREVLEN(p, e->prevrawlensize, e->prevrawlen);    // 获取prevlen的值和长度
    ZIP_DECODE_LENGTH(p + e->prevrawlensize, e->encoding, e->lensize, e->len);  // 获取当前节点的编码方式、长度等
    e->headersize = e->prevrawlensize + e->lensize; // 头大小
    e->p = p;
}
```

**完整的zlentry由以下3各部分组成：**

> 1. prevrawlen：记录前一个节点所占有的内存字节数，通过该值，我们可以从当前节点计算前一个节点的地址，可以用来实现表尾向表头节点遍历；
> 2. len/encoding：记录了当前节点content占有的内存字节数及其存储类型，用来解析content用；
> 3. content：保存了当前节点的值。

最关键的是prevrawlen和len/encoding，content只是实际存储数值的比特位。

**prevrawlen是变长编码，有两种表示方法：**

> 1. 如果前一节点的长度小于 254 字节，则使用1字节(uint8_t)来存储prevrawlen；
> 2. 如果前一节点的长度大于等于 254 字节，那么将第 1 个字节的值设为 254 ，然后用接下来的 4 个字节保存实际长度。

**ziplist使用局限性**
字段、值比较小，才会用ziplist。

**ziplist连锁更新问题**

> 因为在ziplist中，每个zlentry都存储着前一个节点所占的字节数，而这个数值又是变长编码的。假设存在一个压缩列表，其包含e1、e2、e3、e4……，e1节点的大小为253字节，那么e2.prevrawlen的大小为1字节，如果此时在e2与e1之间插入了一个新节点e_new，e_new编码后的整体长度（包含e1的长度）为254字节，此时e2.prevrawlen就需要扩充为5字节；如果e2的整体长度变化又引起了e3.prevrawlen的存储长度变化，那么e3也需要扩…….如此递归直到表尾节点或者某一个节点的prevrawlen本身长度可以容纳前一个节点的变化。其中每一次扩充都需要进行空间再分配操作。删除节点亦是如此，只要引起了操作节点之后的节点的prevrawlen的变化，都可能引起连锁更新。
> 连锁更新在最坏情况下需要进行N次空间再分配，而每次空间再分配的最坏时间复杂度为O(N)，因此连锁更新的总体时间复杂度是O(N^2)。
> 即使涉及连锁更新的时间复杂度这么高，但它能引起的性能问题的概率是极低的：需要列表中存在大量的节点长度接近254的zlentry。
> 由于ziplist连锁更新的问题，也使得ziplist的优缺点极其明显；也使得后续Redis采取折中，替换了ziplist。
> ziplist的主要优点是节省内存，但它上面的查找操作只能按顺序查找（可以是从前往后、也可以从后往前）。
> ziplist将数据按照一定规则编码在一块连续的内存区域，目的是节省内存，这种结构并不擅长做修改操作。一旦数据发生改动，就会引发内存realloc，可能导致内存拷贝。

### 双向链表linkedlist

当链表entry数据超过512、或单个value 长度超过64，底层就会从ziplist转化成linkedlist编码；
linkedlist是标准的双向链表，Node节点包含prev和next指针，可以进行双向遍历；
还保存了 head 和 tail 两个指针，因此，对链表的表头和表尾进行插入的复杂度都为 (1) —— 这是高效实现 LPUSH，RPOP，RPOPLPUSH 等命令的关键。

Redis中的列表list，在版本3.2之前，列表底层的编码是ziplist和linkedlist实现的，但是在版本3.2之后，重新引入 quicklist，列表的底层都由quicklist实现。可以认为quickList，是ziplist和linkedlist二者的结合；quickList将二者的优点结合起来。

### quickList

quickList是一个ziplist组成的双向链表。每个节点使用ziplist来保存数据。本质上来说，quicklist里面保存着一个一个小的ziplist。结构如下：

![在这里插入图片描述](image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzg2MjgyNA==,size_16,color_FFFFFF,t_70-20220413113140048.png)

```c
typedef struct quicklistNode {
    struct quicklistNode *prev; //上一个node节点
    struct quicklistNode *next; //下一个node
    unsigned char *zl;            //保存的数据 压缩前ziplist 压缩后压缩的数据
    unsigned int sz;             /* ziplist size in bytes */
    unsigned int count : 16;     /* count of items in ziplist */
    unsigned int encoding : 2;   /* RAW==1 or LZF==2 */
    unsigned int container : 2;  /* NONE==1 or ZIPLIST==2 */
    unsigned int recompress : 1; /* was this node previous compressed? */
    unsigned int attempted_compress : 1; /* node can't compress; too small */
    unsigned int extra : 10; /* more bits to steal for future usage */
} quicklistNode;

typedef struct quicklistLZF {
    unsigned int sz; /* LZF size in bytes*/
    char compressed[];
} quicklistLZF;

typedef struct quicklist {
    quicklistNode *head; //头结点
    quicklistNode *tail; //尾节点
    unsigned long count;        /* total count of all entries in all ziplists */
    unsigned int len;           /* number of quicklistNodes */
    int fill : 16;              /* fill factor for individual nodes *///负数代表级别，正数代表个数
    unsigned int compress : 16; /* depth of end nodes not to compress;0=off *///压缩级别
} quicklist;
```

quickList就是一个标准的双向链表的配置，有head 有tail;

> 1. 每一个节点是一个quicklistNode，包含prev和next指针。
> 2. 每一个quicklistNode 包含 一个ziplist，*zp 压缩链表里存储键值。

所以quicklist是对ziplist进行一次封装，使用小块的ziplist来既保证了少使用内存，也保证了性能。

### 两种存储方式的优缺点

1. 双向链表linkedlist便于在表的两端进行push和pop操作，在插入节点上复杂度很低，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。
2. ziplist存储在一段连续的内存上，所以存储效率很高。但是，它不利于修改操作，插入和删除操作需要频繁的申请和释放内存。特别是当ziplist长度很长的时候，一次realloc（重新分配存储器）可能会导致大批量的数据拷贝。

## zset与skiplist跳表

**Redis中的zset数据结构是用跳表来实现的**

### skiplist数据结构简介

skiplist本质上也是一种查找结构，用于解决算法中的查找问题（Searching），即根据给定的key，快速查到它所在的位置（或者对应的value）。

我们在《Redis内部数据结构详解》系列的[第一篇](http://zhangtielei.com/posts/blog-redis-dict.html)中介绍dict的时候，曾经讨论过：一般查找问题的解法分为两个大类：一个是基于各种平衡树，一个是基于哈希表。但skiplist却比较特殊，它没法归属到这两大类里面。

这种数据结构是由[William Pugh](https://en.wikipedia.org/wiki/William_Pugh)发明的，最早出现于他在1990年发表的论文《[Skip Lists: A Probabilistic Alternative to Balanced Trees](ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf)》。对细节感兴趣的同学可以下载论文原文来阅读。

skiplist，顾名思义，首先它是一个list。实际上，它是在有序链表的基础上发展起来的。

我们先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）：

[![有序链表结构图](image/sorted_linked_list.png)](http://zhangtielei.com/assets/photos_redis/skiplist/sorted_linked_list.png)

在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点为止（没找到）。也就是说，时间复杂度为O(n)。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。

假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图：

![image-20220316140316176](image/image-20220316140316176.png)

[![每两个节点增加一个跳跃指针的有序链表](image/skip2node_linked_list.png)](http://zhangtielei.com/assets/photos_redis/skiplist/skip2node_linked_list.png)

这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的：

[![一个搜索路径的例子](image/search_path_on_skip2node_list.png)](http://zhangtielei.com/assets/photos_redis/skiplist/search_path_on_skip2node_list.png)

- 23首先和7比较，再和19比较，比它们都大，继续向后比较。
- 但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。
- 23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间。

在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。

利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图：

[![两层跳跃指针](image/skip2node_level3_linked_list.png)](http://zhangtielei.com/assets/photos_redis/skiplist/skip2node_level3_linked_list.png)

在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。

skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。

skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程：

[![skiplist插入形成过程](image/skiplist_insertions.png)](http://zhangtielei.com/assets/photos_redis/skiplist/skiplist_insertions.png)

从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。这在后面我们还会提到。

根据上图中的skiplist结构，我们很容易理解这种数据结构的名字的由来。skiplist，翻译成中文，可以翻译成“跳表”或“跳跃表”，指的就是除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，最终降到第1层链表来精确地确定数据位置。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。

刚刚创建的这个skiplist总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径：

[![skiplist上的查找路径展示](image/search_path_on_skiplist.png)](http://zhangtielei.com/assets/photos_redis/skiplist/search_path_on_skiplist.png)

需要注意的是，前面演示的各个节点的插入过程，实际上在插入之前也要先经历一个类似的查找过程，在确定插入位置后，再完成插入操作。

至此，skiplist的查找和插入操作，我们已经很清楚了。而删除操作与插入操作类似，我们也很容易想象出来。这些操作我们也应该能很容易地用代码实现出来。

当然，实际应用中的skiplist每个节点应该包含key和value两部分。前面的描述中我们没有具体区分key和value，但实际上列表中是按照key进行排序的，查找过程也是根据key在比较。

但是，如果你是第一次接触skiplist，那么一定会产生一个疑问：节点插入时随机出一个层数，仅仅依靠这样一个简单的随机数操作而构建出来的多层链表结构，能保证它有一个良好的查找性能吗？为了回答这个疑问，我们需要分析skiplist的统计性能。

在分析之前，我们还需要着重指出的是，执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。这并不是一个普通的服从均匀分布的随机数，它的计算过程如下：

- 首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。
- 如果一个节点有第i层(i>=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。
- 节点最大的层数不允许超过一个最大值，记为MaxLevel。

这个计算随机层数的伪码如下所示：

```c
randomLevel()
    level := 1
    // random()返回一个[0...1)的随机数
    while random() < p and level < MaxLevel do
        level := level + 1
    return level
```

randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为：

```c
p = 1/4
MaxLevel = 32
```

### skiplist的算法性能分析

在这一部分，我们来简单分析一下skiplist的时间复杂度和空间复杂度，以便对于skiplist的性能有一个直观的了解。如果你不是特别偏执于算法的性能分析，那么可以暂时跳过这一小节的内容。

我们先来计算一下每个节点所包含的平均指针数目（概率期望）。节点包含的指针数目，相当于这个算法在空间上的额外开销(overhead)，可以用来度量空间复杂度。

根据前面randomLevel()的伪码，我们很容易看出，产生越高的节点层数，概率越低。定量的分析如下：

- 节点层数至少为1。而大于1的节点层数，满足一个概率分布。
- 节点层数恰好等于1的概率为1-p。
- 节点层数大于等于2的概率为p，而节点层数恰好等于2的概率为p(1-p)。
- 节点层数大于等于3的概率为p2，而节点层数恰好等于3的概率为p2(1-p)。
- 节点层数大于等于4的概率为p3，而节点层数恰好等于4的概率为p3(1-p)。
- ……

因此，一个节点的平均层数（也即包含的平均指针数目），计算如下：

[![skiplist平均层数计算](image/skiplist_avg_level.jpeg)](http://zhangtielei.com/assets/photos_redis/skiplist/skiplist_avg_level.png)

现在很容易计算出：

- 当p=1/2时，每个节点所包含的平均指针数目为2；
- 当p=1/4时，每个节点所包含的平均指针数目为1.33。这也是Redis里的skiplist实现在空间上的开销。

接下来，为了分析时间复杂度，我们计算一下skiplist的平均查找长度。查找长度指的是查找路径上跨越的跳数，而查找过程中的比较次数就等于查找长度加1。以前面图中标出的查找23的查找路径为例，从左上角的头结点开始，一直到结点22，查找长度为6。

为了计算查找长度，这里我们需要利用一点小技巧。我们注意到，每个节点插入的时候，它的层数是由随机函数randomLevel()计算出来的，而且随机的计算不依赖于其它节点，每次插入过程都是完全独立的。所以，从统计上来说，一个skiplist结构的形成与节点的插入顺序无关。

这样的话，为了计算查找长度，我们可以将查找过程倒过来看，从右下方第1层上最后到达的那个节点开始，沿着查找路径向左向上回溯，类似于爬楼梯的过程。我们假设当回溯到某个节点的时候，它才被插入，这虽然相当于改变了节点的插入顺序，但从统计上不影响整个skiplist的形成结构。

现在假设我们从一个层数为i的节点x出发，需要向左向上攀爬k层。这时我们有两种可能：

- 如果节点x有第(i+1)层指针，那么我们需要向上走。这种情况概率为p。
- 如果节点x没有第(i+1)层指针，那么我们需要向左走。这种情况概率为(1-p)。

这两种情形如下图所示：

[![skiplist沿查找路径回溯](image/skiplist_backwards.jpeg)](http://zhangtielei.com/assets/photos_redis/skiplist/skiplist_backwards.png)

用C(k)表示向上攀爬k个层级所需要走过的平均查找路径长度（概率期望），那么：

```c
C(0)=0
C(k)=(1-p)×(上图中情况b的查找长度) + p×(上图中情况c的查找长度)
```

代入，得到一个差分方程并化简：

```c
C(k)=(1-p)(C(k)+1) + p(C(k-1)+1)
C(k)=1/p+C(k-1)
C(k)=k/p
```

这个结果的意思是，我们每爬升1个层级，需要在查找路径上走1/p步。而我们总共需要攀爬的层级数等于整个skiplist的总层数-1。

那么接下来我们需要分析一下当skiplist中有n个节点的时候，它的总层数的概率均值是多少。这个问题直观上比较好理解。根据节点的层数随机算法，容易得出：

- 第1层链表固定有n个节点；
- 第2层链表平均有n*p个节点；
- 第3层链表平均有n*p2个节点；
- …

所以，从第1层到最高层，各层链表的平均节点数是一个指数递减的等比数列。容易推算出，总层数的均值为log1/pn，而最高层的平均节点数为1/p。

综上，粗略来计算的话，平均查找长度约等于：

- C(log1/pn-1)=(log1/pn-1)/p

即，平均时间复杂度为O(log n)。

当然，这里的时间复杂度分析还是比较粗略的。比如，沿着查找路径向左向上回溯的时候，可能先到达左侧头结点，然后沿头结点一路向上；还可能先到达最高层的节点，然后沿着最高层链表一路向左。但这些细节不影响平均时间复杂度的最后结果。另外，这里给出的时间复杂度只是一个概率平均值，但实际上计算一个精细的概率分布也是有可能的。详情还请参见[William Pugh](https://en.wikipedia.org/wiki/William_Pugh)的论文《[Skip Lists: A Probabilistic Alternative to Balanced Trees](ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf)》。

### skiplist与平衡树、哈希表的比较

- skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
- 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
- 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。
- 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
- 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
- 从算法实现难度上来比较，skiplist比平衡树要简单得多。

### Redis中的skiplist实现

在这一部分，我们讨论Redis中的skiplist实现。

在Redis中，skiplist被用于实现暴露给外部的一个数据结构：sorted set。准确地说，sorted set底层不仅仅使用了skiplist，还使用了ziplist和dict。这几个数据结构的关系，我们下一章再讨论。现在，我们先花点时间把sorted set的关键命令看一下。这些命令对于Redis里skiplist的实现，有重要的影响。

#### sorted set的命令举例

sorted set是一个有序的数据集合，对于像类似排行榜这样的应用场景特别适合。

现在我们来看一个例子，用sorted set来存储代数课（algebra）的成绩表。原始数据如下：

- Alice 87.5
- Bob 89.0
- Charles 65.5
- David 78.0
- Emily 93.5
- Fred 87.5

这份数据给出了每位同学的名字和分数。下面我们将这份数据存储到sorted set里面去：

[![sorted set命令举例](image/sorted_set_cmd_examples.jpeg)](http://zhangtielei.com/assets/photos_redis/skiplist/sorted_set_cmd_examples.png)

对于上面的这些命令，我们需要的注意的地方包括：

- 前面的6个zadd命令，将6位同学的名字和分数(score)都输入到一个key值为algebra的sorted set里面了。注意Alice和Fred的分数相同，都是87.5分。
- zrevrank命令查询Alice的排名（命令中的rev表示按照倒序排列，也就是从大到小），返回3。排在Alice前面的分别是Emily、Bob、Fred，而排名(rank)从0开始计数，所以Alice的排名是3。注意，其实Alice和Fred的分数相同，这种情况下sorted set会把分数相同的元素，按照字典顺序来排列。按照倒序，Fred排在了Alice的前面。
- zscore命令查询了Charles对应的分数。
- zrevrange命令查询了从大到小排名为0~3的4位同学。
- zrevrangebyscore命令查询了分数在80.0和90.0之间的所有同学，并按分数从大到小排列。

总结一下，sorted set中的每个元素主要表现出3个属性：

- 数据本身（在前面的例子中我们把名字存成了数据）。
- 每个数据对应一个分数(score)。
- 根据分数大小和数据本身的字典排序，每个数据会产生一个排名(rank)。可以按正序或倒序。

#### Redis中skiplist实现的特殊性

我们简单分析一下前面出现的几个查询命令：

- zrevrank由数据查询它对应的排名，这在前面介绍的skiplist中并不支持。
- zscore由数据查询它对应的分数，这也不是skiplist所支持的。
- zrevrange根据一个排名范围，查询排名在这个范围内的数据。这在前面介绍的skiplist中也不支持。
- zrevrangebyscore根据分数区间查询数据集合，是一个skiplist所支持的典型的范围查找（score相当于key）。

实际上，Redis中sorted set的实现是这样的：

- 当数据较少时，sorted set是由一个ziplist来实现的。
- 当数据多的时候，sorted set是由一个dict + 一个skiplist来实现的。简单来讲，dict用来查询数据到分数的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。

这里sorted set的构成我们在下一章还会再详细地讨论。现在我们集中精力来看一下sorted set与skiplist的关系，：

- zscore的查询，不是由skiplist来提供的，而是由那个dict来提供的。
- 为了支持排名(rank)，Redis里对skiplist做了扩展，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。而且，根据排名的查找，时间复杂度也为O(log n)。
- zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。
- zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。

前述的查询过程，也暗示了各个操作的时间复杂度：

- zscore只用查询一个dict，所以时间复杂度为O(1)
- zrevrank, zrevrange, zrevrangebyscore由于要查询skiplist，所以zrevrank的时间复杂度为O(log n)，而zrevrange, zrevrangebyscore的时间复杂度为O(log(n)+M)，其中M是当前查询返回的元素个数。

总结起来，Redis中的skiplist跟前面介绍的经典的skiplist相比，有如下不同：

- 分数(score)允许重复，即skiplist的key允许重复。这在最开始介绍的经典skiplist中是不允许的。
- 在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。
- 第1层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。
- 在skiplist中可以很方便地计算出每个元素的排名(rank)。

#### skiplist的数据结构定义

```c
#define ZSKIPLIST_MAXLEVEL 32
#define ZSKIPLIST_P 0.25

typedef struct zskiplistNode {
    robj *obj;
    double score;
    struct zskiplistNode *backward;
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned int span;
    } level[];
} zskiplistNode;

typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;
```

这段代码出自server.h，我们来简要分析一下：

- 开头定义了两个常量，ZSKIPLIST_MAXLEVEL和ZSKIPLIST_P，分别对应我们前面讲到的skiplist的两个参数：一个是MaxLevel，一个是p。
- zskiplistNode定义了skiplist的节点结构。
  - obj字段存放的是节点数据，它的类型是一个string robj。本来一个string robj可能存放的不是sds，而是long型，但zadd命令在将数据插入到skiplist里面之前先进行了解码，所以这里的obj字段里存储的一定是一个sds。有关robj的详情可以参见系列文章的第三篇：《[Redis内部数据结构详解(3)——robj](http://zhangtielei.com/posts/blog-redis-robj.html)》。这样做的目的应该是为了方便在查找的时候对数据进行字典序的比较，而且，skiplist里的数据部分是数字的可能性也比较小。
  - score字段是数据对应的分数。
  - backward字段是指向链表前一个节点的指针（前向指针）。节点只有1个前向指针，所以只有第1层链表是一个双向链表。
  - level[]存放指向各层链表后一个节点的指针（后向指针）。每层对应1个后向指针，用forward字段表示。另外，每个后向指针还对应了一个span值，它表示当前的指针跨越了多少个节点。span用于计算元素排名(rank)，这正是前面我们提到的Redis对于skiplist所做的一个扩展。需要注意的是，level[]是一个柔性数组（[flexible array member](https://en.wikipedia.org/wiki/Flexible_array_member)），因此它占用的内存不在zskiplistNode结构里面，而需要插入节点的时候单独为它分配。也正因为如此，skiplist的每个节点所包含的指针数目才是不固定的，我们前面分析过的结论——skiplist每个节点包含的指针数目平均为1/(1-p)——才能有意义。
- zskiplist定义了真正的skiplist结构，它包含：
  - 头指针header和尾指针tail。
  - 链表长度length，即链表包含的节点总数。注意，新创建的skiplist包含一个空的头指针，这个头指针不包含在length计数中。
  - level表示skiplist的总层数，即所有节点层数的最大值。

下图以前面插入的代数课成绩表为例，展示了Redis中一个skiplist的可能结构：

[![Redis skiplist结构举例](image/redis_skiplist_example.png)](http://zhangtielei.com/assets/photos_redis/skiplist/redis_skiplist_example.png)

注意：图中前向指针上面括号中的数字，表示对应的span的值。即当前指针跨越了多少个节点，这个计数不包括指针的起点节点，但包括指针的终点节点。

假设我们在这个skiplist中查找score=89.0的元素（即Bob的成绩数据），在查找路径中，我们会跨域图中标红的指针，这些指针上面的span值累加起来，就得到了Bob的排名(2+2+1)-1=4（减1是因为rank值以0起始）。需要注意这里算的是从小到大的排名，而如果要算从大到小的排名，只需要用skiplist长度减去查找路径上的span累加值，即6-(2+2+1)=1。

可见，在查找skiplist的过程中，通过累加span值的方式，我们就能很容易算出排名。相反，如果指定排名来查找数据（类似zrange和zrevrange那样），也可以不断累加span并时刻保持累加值不超过指定的排名，通过这种方式就能得到一条O(log n)的查找路径。

### Redis中的sorted set

我们前面提到过，Redis中的sorted set，是在skiplist, dict和ziplist基础上构建起来的:

- 当数据较少时，sorted set是由一个ziplist来实现的。
- 当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个dict + 一个skiplist。dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。

在这里我们先来讨论一下前一种情况——基于ziplist实现的sorted set。在本系列前面[关于ziplist的文章](http://zhangtielei.com/posts/blog-redis-ziplist.html)里，我们介绍过，ziplist就是由很多数据项组成的一大块连续内存。由于sorted set的每一项元素都由数据和score组成，因此，当使用zadd命令插入一个(数据, score)对的时候，底层在相应的ziplist上就插入两个数据项：数据在前，score在后。

ziplist的主要优点是节省内存，但它上面的查找操作只能按顺序查找（可以正序也可以倒序）。因此，sorted set的各个查询操作，就是在ziplist上从前向后（或从后向前）一步步查找，每一步前进两个数据项，跨域一个(数据, score)对。

随着数据的插入，sorted set底层的这个ziplist就可能会转成zset的实现（转换过程详见t_zset.c的zsetConvert）。那么到底插入多少才会转呢？

还记得本文开头提到的两个Redis配置吗？

```
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
```

这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成zset（具体的触发条件参见t_zset.c中的zaddGenericCommand相关代码）：

- 当sorted set中的元素个数，即(数据, score)对的数目超过128的时候，也就是ziplist数据项超过256的时候。
- 当sorted set中插入的任意一个数据的长度超过了64的时候。

最后，zset结构的代码定义如下：

```c
typedef struct zset {
    dict *dict;
    zskiplist *zsl;
} zset;
```

### Redis为什么用skiplist而不用平衡树？

在前面我们对于skiplist和平衡树、哈希表的比较中，其实已经不难看出Redis里使用skiplist而不用平衡树的原因了。现在我们看看，对于这个问题，Redis的作者 @antirez 是怎么说的：

> There are a few reasons:
>
> \1) They are not very memory intensive. It’s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.
>
> \2) A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.
>
> \3) They are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.

这段话原文出处：

> https://news.ycombinator.com/item?id=1171423

这里从内存占用、对范围查找的支持和实现难易程度这三方面总结的原因，我们在前面其实也都涉及到了。

## Redis中skiplist的具体使用

### 数据结构定义

有许多数据结构的定义其实是按照（结点+组织方式）来的，结点就是一个数据点，组织方式就是把结点组织起来形成数据结构，比如 双端链表 (ListNode+list)、字典（dictEntry+dictht+dict）等，今天所说的SkipList其实也一样，我们首先看下它的结点定义：

```c
typedef struct zskiplistNode {     
    sds ele;                              //数据域
    double score;                         //分值 
    struct zskiplistNode *backward;       //后向指针，使得跳表第一层组织为双向链表
    struct zskiplistLevel {               //每一个结点的层级
        struct zskiplistNode *forward;    //某一层的前向结点
        unsigned int span;                //某一层距离下一个结点的跨度
    } level[];                            //level本身是一个柔性数组，最大值为32，由 ZSKIPLIST_MAXLEVEL 定义
} zskiplistNode;
```

接下来是组织方式，即使用上面的`zskiplistNode`组织起一个SkipList：

```c
typedef struct zskiplist {
    struct zskiplistNode *header;     //头部
    struct zskiplistNode *tail;       //尾部
    unsigned long length;             //长度，即一共有多少个元素
    int level;                        //最大层级，即跳表目前的最大层级
} zskiplist;
```

核心的数据结构就是上面两个。

### 创建、插入、查找、删除、释放

我们以下面这个例子来跟踪SkipList的代码，其中会涉及到的操作有`创建、插入、查找、删除、释放`等。（ps:将Redis中main函数的代码替换成下面的代码就可以测试）

```c
// 需要声明下 zslGetElementByRank() 函数，main函数中使用
zkiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank);

int main(int argc, char **argv) {
  
    unsigned long ret;
    zskiplistNode *node;
    zskiplist *zsl = zslCreate();

    zslInsert(zsl, 65.5, sdsnew("tom"));             //level = 1
    zslInsert(zsl, 87.5, sdsnew("jack"));            //level = 4
    zslInsert(zsl, 70.0, sdsnew("alice"));           //level = 3
    zslInsert(zsl, 95.0, sdsnew("tony"));            //level = 2

    zrangespec spec = {                      //定义一个区间， 70.0 <= x <= 90.0
            .min = 70.0,
            .max = 90.0,
            .minex = 0,
            .maxex = 0};

    printf("zslFirstInRange 70.0 <= x <= 90.0, x is:");  // 找到符合区间的最小值
    node = zslFirstInRange(zsl, &spec);
    printf("%s->%f\n", node->ele, node->score);

    printf("zslLastInRange 70.0 <= x <= 90.0, x is:");   // 找到符合区间的最大值
    node = zslLastInRange(zsl, &spec);
    printf("%s->%f\n", node->ele, node->score);

    printf("tony's Ranking is :");                       // 根据分数获取排名
    ret = zslGetRank(zsl, 95.0, sdsnew("tony"));
    printf("%lu\n", ret);

    printf("The Rank equal 4 is :");                     // 根据排名获取分数
    node = zslGetElementByRank(zsl, 4);
    printf("%s->%f\n", node->ele, node->score);

    ret = zslDelete(zsl, 70.0, sdsnew("alice"), &node);  // 删除元素
    if (ret == 1) {
        printf("Delete node:%s->%f success!\n", node->ele, node->score);
    }

    zslFree(zsl);                                        // 释放zsl

    return 0;
}

Out > 
zslFirstInRange 70.0 <= x <= 90.0, x is:alice->70.000000
zslLastInRange 70.0 <= x <= 90.0, x is:jack->87.500000
tony's Ranking is :4
The Rank equal 4 is :tony->95.000000
Delete node:alice->70.000000 success!
```

接下来我们逐行分析代码，首先zskiplist *zsl = zslCreate();创建了一个SkipList，需要关注的重点是会初始化zsl->header为最大层级32，因为 ZSKIPLIST_MAXLEVEL 定义为32，这个原因与SkipList中获取Level的随机函数有关，具体参考文章开头给的博客链接。我们看下zslCreate的代码：

```c
zskiplist *zslCreate(void) {
    int j;
    zskiplist *zsl;

    zsl = zmalloc(sizeof(*zsl));                             // 申请空间
    zsl->level = 1;                                          // 初始层级定义为1
    zsl->length = 0;
    zsl->header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);  // 初始化header为32层
    for (j = 0; j < ZSKIPLIST_MAXLEVEL; j++) {
        zsl->header->level[j].forward = NULL;
        zsl->header->level[j].span = 0;
    }
    zsl->header->backward = NULL;    
    zsl->tail = NULL;                                        // tail目前为NULL
    return zsl; 
}

// zslCreateNode根据传入的level和score以及ele创建一个level层的zskiplistNode
zskiplistNode *zslCreateNode(int level, double score, sds ele) { 
    zskiplistNode *zn =
        zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel));
    zn->score = score;
    zn->ele = ele;
    return zn;
}
```

目前我们的zsl如下图所示： 

![这里写图片描述](https://img-blog.csdn.net/20171113193414265)

- 接下来我们开始向zsl中插入数据，`zslInsert(zsl, 65.5, sdsnew("tom"));`zslInsert的代码如下所示：

```c
zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) {

    /* 虽然整个代码较长，但是从整体逻辑上可以分为三部分：
    *  1：根据目前传入的score找到插入位置x，这个过程会保存各层x的前一个位置节点  
    *    就像我们对有序单链表插入节点的时候先要找到比目前数字小的节点保存下来。
    *  2：根据随机函数获取level，生成新的节点
    *  3：修改各个指针的指向，将创建的新节点插入。
    */ 

    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;
    unsigned int rank[ZSKIPLIST_MAXLEVEL];
    int i, level;

    /* 第一步: 根据目前传入的score找到插入位置x，并且将各层的前置节点保存至rank[]中 */
    serverAssert(!isnan(score));
    x = zsl->header;
    for (i = zsl->level-1; i >= 0; i--) {
        /* store rank that is crossed to reach the insert position */
        rank[i] = i == (zsl->level-1) ? 0 : rank[i+1];
        while (x->level[i].forward &&
                (x->level[i].forward->score < score ||
                    (x->level[i].forward->score == score &&
                    sdscmp(x->level[i].forward->ele,ele) < 0)))
        {
            rank[i] += x->level[i].span;
            x = x->level[i].forward;
        }
        update[i] = x;
    }
    /* we assume the element is not already inside, since we allow duplicated
     * scores, reinserting the same element should never happen since the
     * caller of zslInsert() should test in the hash table if the element is
     * already inside or not. */

    /* 第二步：获取level，生成新的节点 */
    level = zslRandomLevel();                
    if (level > zsl->level) {
        for (i = zsl->level; i < level; i++) {
            rank[i] = 0;
            update[i] = zsl->header;
            update[i]->level[i].span = zsl->length;
        }
        zsl->level = level;
    }
    x = zslCreateNode(level,score,ele);

    /* 第三步：修改各个指针的指向，将创建的新节点插入 */
    for (i = 0; i < level; i++) {
        x->level[i].forward = update[i]->level[i].forward;
        update[i]->level[i].forward = x;

        /* update span covered by update[i] as x is inserted here */
        x->level[i].span = update[i]->level[i].span - (rank[0] - rank[i]);
        update[i]->level[i].span = (rank[0] - rank[i]) + 1;
    }

    /* increment span for untouched levels */
    for (i = level; i < zsl->level; i++) {
        update[i]->level[i].span++;
    }

    /* 更新backword的指向 */
    x->backward = (update[0] == zsl->header) ? NULL : update[0];
    if (x->level[0].forward)
        x->level[0].forward->backward = x;
    else
        zsl->tail = x;
    zsl->length++;
    return x;
}
```

需要注意的是span的含义，它表示`当前节点距离下一个节点的跨度`，之所以可以根据rank排名获取元素，就是根据span确定的。update[i]保存的就是第 i 层应该插入节点的前一个节点，在第三步更新指针的时候使用。插入了一个元素的zsl如下图所示(level=1)：

![这里写图片描述](https://img-blog.csdn.net/20171113193956487)

- 接着我们继续插入后面的三条数据，他们的level分别为`jack->4、alice->3、tony->2`,此时的zsl如下图所示，注意span的更新：

![这里写图片描述](https://img-blog.csdn.net/20171113194041499)

- 好了，插入终于结束啦！接下来我们看下查找的相关操作，上面的代码中有关查找举了4个例子，分别是： 
  1）查找指定范围内最小的元素 
  2）查找指定范围内最大的元素 
  3）根据名称获取排名 
  4）根据排名获取名称

我们分析下（1）和（4），（2）、（3）同理。首先来看（1），用zrangespec结构体定义了一个范围为`70.0 <= x <= 90.0`，有关zrangespec结构体如下所示：

```c
typedef struct {
    double min, max;    // 定义最小范围和最大范围
    int minex, maxex;   // 是否包含最小和最大本身，为 0 表示包含，1 表示不包含
} zrangespec;

/* 定义范围的代码如下所示 */
zrangespec spec = {                      //定义spec， 70.0 <= x <= 90.0
            .min = 70.0,                
            .max = 90.0,
            .minex = 0,
            .maxex = 0};                 //为结构体元素赋值
```

下面调用`zslFirstInRange()`函数遍历得到了满足`70.0 <= x <= 90.0`的最小节点，代码如下：

```c
/* Find the first node that is contained in the specified range.
 * Returns NULL when no element is contained in the range. */
zskiplistNode *zslFirstInRange(zskiplist *zsl, zrangespec *range) {
    zskiplistNode *x;
    int i;

    /* If everything is out of range, return early. */
    if (!zslIsInRange(zsl,range)) return NULL;                // 判断给定的范围是否合法

    x = zsl->header;   
    for (i = zsl->level-1; i >= 0; i--) {                     // 从最高的Level开始 
        /* Go forward while *OUT* of range. */                
        while (x->level[i].forward &&                         //只要没结束 && 目前结点的score小于目标score
            !zslValueGteMin(x->level[i].forward->score,range))
            // 将结点走到当前的节点
                x = x->level[i].forward;
    }

    /* This is an inner range, so the next node cannot be NULL. */
    x = x->level[0].forward;                                 // 找到了符合的点
    serverAssert(x != NULL);       

    /* Check if score <= max. */
    if (!zslValueLteMax(x->score,range)) return NULL;       // 判断返回的值是否小于max值
    return x;
}
```

可以看到，遍历的核心思想是: 
(1) 高Level -> 低Level 
(2) 小score -> 大score 
即在从高Level遍历比较过程中，如果此时的score小于了某个高level的值，就在这个节点前一个节点降低一层Level继续往前遍历，我们找70.0的路线如下图所示（图中红线）：

![这里写图片描述](https://img-blog.csdn.net/20171113194253339)

- 继续看下根据排名获取元素的函数`zslGetElementByRank()`，主要是根据span域来完成，代码如下所示:

```c
zskiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank) {
    zskiplistNode *x;
    unsigned long traversed = 0;
    int i;

    x = zsl->header;
    for (i = zsl->level-1; i >= 0; i--) {
        while (x->level[i].forward && (traversed + x->level[i].span) <= rank)
        {
            traversed += x->level[i].span;
            x = x->level[i].forward;
        }
        if (traversed == rank) {
            return x;
        }
    }
    return NULL;
}
```

遍历的思想和之前没有什么差别，本次遍历路线如下图所示:

![这里写图片描述](https://img-blog.csdn.net/20171113194331946)

接着我们看下Delete()函数，ret = zslDelete(zsl, 70.0, sdsnew("alice"), &node); 表示删除zsl中score为70.0，数据为alice的元素，这也是Redis SkipList的第二个特征，比较一个元素不仅比较score,而且比较数据，下面看下zslDelete的代码:

```c
int zslDelete(zskiplist *zsl, double score, sds ele, zskiplistNode **node) {
    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;
    int i;

    x = zsl->header;
    for (i = zsl->level-1; i >= 0; i--) {
        while (x->level[i].forward &&
                (x->level[i].forward->score < score ||
                    (x->level[i].forward->score == score &&
                     sdscmp(x->level[i].forward->ele,ele) < 0)))
        {
            x = x->level[i].forward;
        }
        update[i] = x;
    }
    /* We may have multiple elements with the same score, what we need
     * is to find the element with both the right score and object. */
    x = x->level[0].forward;
    if (x && score == x->score && sdscmp(x->ele,ele) == 0) {
        zslDeleteNode(zsl, x, update);
        if (!node)
            zslFreeNode(x);
        else
            *node = x;
        return 1;
    }
    return 0; /* not found */
}
```

- 需要注意的是zslDelete()第四个参数，是一个zskipListNode **类型，它如果不为NULL，那么代码在遍历找到node之后不会将其直接释放，而是将地址交给它，后续这块空间的释放就必须由我们手动处理。
- 遍历比较的思想和之前还是一样， 在update[]中记录下各层删除节点之前的节点。
- while循环比较条件，sdscmp(x->level[i].forward->ele,ele) < 0是因为插入函数zslInsert()也是按照这个逻辑插入的。
- 最后需要再次比较if (x && score == x->score && sdscmp(x->ele,ele) == 0)是因为Redis SkipList允许相同score的元素存在。

最后看看释放函数`zslFree(zsl)`，思想很简单，因为level[0]一定是连续的（并且是一个双向链表），所以从level[0]依次遍历释放就行了。

```c
/* Free a whole skiplist. */
void zslFree(zskiplist *zsl) {
    zskiplistNode *node = zsl->header->level[0].forward, *next;

    zfree(zsl->header);
    while(node) {
        next = node->level[0].forward;
        zslFreeNode(node);
        node = next;
    }
    zfree(zsl);
}
```

通过上面的例子，我们分析了zskiplist的`创建、插入、查找、删除、释放`等操作，结合数据结构的定义，基本上分析清楚了zskiplist。其实zskiplist在Redis中的主要用处是和dict一起实现`Sorted Set`，这个我们后续看Sorted Set的时候再分析。

### 性能分析

| 操作 | 一般性能 | 最坏性能 |
| ---- | -------- | -------- |
| 插入 | O(log n) | O(n)     |
| 删除 | O(log n) | O(n)     |
| 搜索 | O(log n) | O(n)     |

## 从源码看redis写入一个key需要多大的内存

### redis字典

说起redis的数据结构，字典是最底层的数据结构了。《redis设计与实现》一书中对字典的定义：

> 字典，又称为符号表(Symbol table)、关联数组(associative array)或映射(map)，是一种用于保存键值对(key-value pair)的抽象数据结构。

**redis构建了自己的字典实现，redis中的数据库就是使用字典来作为底层实现的，redis中的哈希键(Hash)也使用字典来实现的。**

而redis的字典又是使用哈希表来作为底层实现的。哈希算法采用的是MurmurHash2算法，一个优秀的哈希算法有如下要求：

1. **雪崩效应**(任何输入的微小变化都会导致巨大的差异)
2. **低碰撞率**
3. **高性能**

关于Murmurhash算法详情以及实际应用可阅读我的文章：MurmurHash算法及应用场景

在安装的redis/src文件夹下可以看到有很多后缀名为.h、.c、.o的文件，其中.h代表的是.c文件中用到的变量、数组、函数的声明，.c文件是.h文件中声明的变量、数组、函数具体的定义，而.o就是编译后的汇编文件。

大家可以看到有dict.h文件，这个文件里面即定义了字典的数据结构，**我们打开源码可以看到如下四个C语言的结构体(struct)**：

```cpp
typedef struct dictEntry {    void *key;    union {        void *val;        uint64_t u64;        int64_t s64;        double d;    } v;    struct dictEntry *next;} dictEntry;

typedef struct dictType {    uint64_t (*hashFunction)(const void *key);    void *(*keyDup)(void *privdata, const void *key);    void *(*valDup)(void *privdata, const void *obj);    int (*keyCompare)(void *privdata, const void *key1, const void *key2);    void (*keyDestructor)(void *privdata, void *key);    void (*valDestructor)(void *privdata, void *obj);} dictType;

typedef struct dictht {    dictEntry **table;    unsigned long size;    unsigned long sizemask;    unsigned long used;} dictht;

typedef struct dict {    dictType *type;    void *privdata;    dictht ht[2];    long rehashidx; /* rehashing not in progress if rehashidx == -1 */    unsigned long iterators; /* number of iterators currently running */} dict;
```

用一张图来表述他们之间的关系如下：

![89674906e598b7a68967db486a425512.png](image/89674906e598b7a68967db486a425512.jpeg)

当我们执行一条如下语句的时候：

```redis
set testKey testValue
```

如果是首次redis写入，会创建一个dict字典对象，**字典对象的数据**如下：

![e1dd6478ed8177d71a629c66fc2422d8.png](image/e1dd6478ed8177d71a629c66fc2422d8.jpeg)

当然如果你写入的不是字符串类型的数据类型，而是List、Hash、Set、ZSet四种数据，也和上图的数据结构一样，只是dictEntry里面的值对象val指针会指向不同的对象，不同的对象会有不同的数据结构，**强烈推荐大家阅读《redis设计与实现》这本书，深读此书将会彻底搞清楚redis**。

### redis内存计算

上节从redis的字典说了redis的底层数据结构是如何保存我们写入的key的，那么当我们执行命令写入key到redis中，redis的内存具体是如何分配的呢？我们一起来实验一下：

首先执行**FLUSHALL**命令来清空我们的redis，保证没有其他key干扰，然后执行：

```perl
src/redis-cli info | grep mem
```

获取redis初始内存信息：

![d643986f3d9d55902514d41f72bf1c7a.png](image/d643986f3d9d55902514d41f72bf1c7a.jpeg)

关键属性说明如下(更多属性说明请查阅redis官网)：

![905038cdb6ee08fb1554a6ee4d8ca621.png](image/905038cdb6ee08fb1554a6ee4d8ca621.jpeg)

redis初始占用内存：**1039472字节**，当我们执行:

```python
set testKey testValue
```

再查看内存变化为：

![de649ee3faf5cf9094b7f52586b6b9d0.png](image/de649ee3faf5cf9094b7f52586b6b9d0.jpeg)

也就是说上面的语句执行后吃了redis内存为：1057472-1039472=18000b=17.58K，那是不是代表上面的执行吃了18K的内存呢？

我们再写入一个key：

```python
set testKey1 testValue1
```

通过上文对字典的描述可以知道testKey1在redis中的存储应该如下图所示：

![1088e42d4ca4331cb77e7dddd6049186.png](image/1088e42d4ca4331cb77e7dddd6049186.jpeg)

查看内存变化为：

**used_memory:1057552**

才发现吃了80字节的内存。

所以我们可以知道的是redis启动之后需要占用一部分内存，这部分内存1039472字节用于redis服务的运行以及初始化一些数据。另外首次写入redis的key之后，需要构造上文所说的redis字典结构，因此需要占用一些内存。

我们需要知道的是当我们写入一个key的时候占用的内存到底是多少，由于我们写的值都没有超过44个字节，所以采用EMBSTR数据结构存储。所以我们可以查看object.c源码里面是如何创建对象的：

![38f2d12ffa7d13d5fb6cd16b0f51a8cd.png](image/38f2d12ffa7d13d5fb6cd16b0f51a8cd.jpeg)

![ee2869ec9c28c1c30fe2c562eb40f564.png](image/ee2869ec9c28c1c30fe2c562eb40f564.jpeg)

分配内存的代码：

```csharp
robj *o = zmalloc(sizeof(robj)+sizeof(struct sdshdr8)+len+1);
```

可以看到redis为我们分配了：

```csharp
sizeof(robj)+sizeof(struct sdshdr8)+len+1
```

这么大的内存，其中的robj代表的是redisObject，查看server.h中关于redisObject对象的定义：

![3f7f8e7018f227181b668ce47ded813b.png](image/3f7f8e7018f227181b668ce47ded813b.jpeg)

因此sizeof(robj) = 16字节。

sdshdr8即上图中的sdshdr中的头部3个字节。

因此testValue1这个采用EMBSTR编码的存储需要内存：16+3+10+1=30字节，redis内存分配器为其分配32字节。

我们再来计算testKey1占用的内存，testKey1存储的就是一个SDS简单动态对象，少了robj的内存占用，因此需要内存：3+8+1 = 12字节，redis分配器为其分配16字节。

总共需要内存为32+16=48字节，那为什么占用的是80字节呢？剩下的32字节谁吃了呢？大家不要忘记了dictEntry这个结构还有三个指针呢：

![58f6951e2a4d31d6825a319fb0334208.png](image/58f6951e2a4d31d6825a319fb0334208.jpeg)

三个指针占用内存：3*8-24字节，jemalloc会为其分配32个字节。

至此，我们便能清晰的知道当我们执行一个字符串对象(字符串长度不超过44！)写入的时候，需要占用内存多少了。

即**80-18(testKey1&testValue1) = 62**的长度。但是我们需要知道这62个长度都吃在什么地方了。

上面说的是当写入String类型的数据且长度值不超过44的时候占用的内存计算方法。其他数据类型如List、Hash、Set、Zset大家可以参考我上面的方法和思路并查看相关redis源码以及redis技术资料即可得知。

### redis-benchmark[压测](https://so.csdn.net/so/search?q=压测&spm=1001.2101.3001.7020)

src目录下redis-benchmark是redis自带的压测工具，压测语法格式：

```css
redis-benchmark [option] [option value]
```

option可选参数如下：

![30f6e523fed0ef83a9601b3c27190256.png](image/30f6e523fed0ef83a9601b3c27190256.jpeg)

执行压测语句：

```css
src/redis-benchmark -p 6379 -t set -c 100 -n 1000000 -r 1000000
```

输出压测结果：

```sql
➜  redis-5.0.7 src/redis-benchmark -p 6379 -t set -c 100 -n 1000000 -r 1000000====== SET ======  1000000 requests completed in 20.04 seconds  100 parallel clients  3 bytes payload  keep alive: 144.04% <= 1 milliseconds96.99% <= 2 milliseconds98.73% <= 3 milliseconds99.29% <= 4 milliseconds99.53% <= 5 milliseconds99.68% <= 6 milliseconds99.76% <= 7 milliseconds99.81% <= 8 milliseconds99.85% <= 9 milliseconds99.90% <= 10 milliseconds99.92% <= 11 milliseconds99.93% <= 12 milliseconds99.94% <= 13 milliseconds99.95% <= 14 milliseconds99.96% <= 15 milliseconds99.96% <= 16 milliseconds99.96% <= 17 milliseconds99.97% <= 18 milliseconds99.97% <= 19 milliseconds99.97% <= 20 milliseconds99.97% <= 21 milliseconds99.98% <= 22 milliseconds99.98% <= 23 milliseconds99.98% <= 24 milliseconds99.98% <= 25 milliseconds99.98% <= 26 milliseconds99.98% <= 27 milliseconds99.98% <= 28 milliseconds99.98% <= 31 milliseconds99.98% <= 32 milliseconds99.98% <= 33 milliseconds99.99% <= 34 milliseconds99.99% <= 35 milliseconds99.99% <= 36 milliseconds99.99% <= 37 milliseconds99.99% <= 38 milliseconds100.00% <= 39 milliseconds100.00% <= 41 milliseconds100.00% <= 50 milliseconds100.00% <= 58 milliseconds100.00% <= 58 milliseconds49907.67 requests per second
```

压测完毕后执行**src/redis-cli info | grep mem**命令查看内存占用情况：

![e97c44af421a1bd642c275d30282f16f.png](image/e97c44af421a1bd642c275d30282f16f.jpeg)

共占用内存：**70084048-1039472=69044576字节=65.85M**

![d2df33b4495fa288431f93bcb22fcd25.png](image/d2df33b4495fa288431f93bcb22fcd25.jpeg)

总共写入631833个key，每个key的内容格式如下：

**set key:000000075890 xxx**

即每个key占用内存为：32+32+32=96字节，共消耗：631833*96=57.85M，我们压测的info总共消耗65.85M，还差8M去哪里了呢？

还记得第一部分说的字典结构里面的ht[0]和ht[1]么？初始ht[0]为4，分配的内存就是4*8b=32b，当需要存储的数据超过4个的时候就会触发rehash动作，将ht[1]扩容为ht[0]的2倍，然后将h[0]里的数据全部rehash至ht[1]，再互相交换一下，ht[1]变成ht[0]，ht[0]变成ht[1]。那么当我们写入的631833个key将会产生rehash多少次呢？

```undefined
realsize=4realsize=8realsize=16realsize=32realsize=64realsize=128realsize=256realsize=512realsize=1024realsize=2048realsize=4096realsize=8192realsize=16384realsize=32768realsize=65536realsize=131072realsize=262144realsize=524288realsize=1048576
```

所以目前realsize是1048576，那么总共需要分配的内存就是**1048576\*8= 8388608，8388608/1024/1024=8MB**，刚好和我们压测的结果对上了！

### 总结

以上就是redis关于内存分配的相关知识了。上面只是对redis的字符串类型的数据进行解说，通过对字符串类型的部分源码解读我们可以清楚的知道一个key的写入到redis需要多大的内存。其他的数据结构这里没有做详细说明，但其实思路是一致的。让我们再看一下下图dictEntry对象的定义，从字典开始，前面的都一致，只是dictEntry里面的*val指向不同而已。

![f827b943ade5c1261de17016d253d78d.png](image/f827b943ade5c1261de17016d253d78d.jpeg)

## Redis基础数据结构-字典（详解）

  redis的字典hash相当于Java里面的HashMap，实现结构上也与Java的HashMap一样，都是“数组+链表”的二维结构。
 不同的是，redis的字典的值只能是字符串，并且它们rehash的方式也不一样，相较于Java中HashMap的一次性rehash，redis中是渐进式rehash。
  hash结构用来存储用户信息时，与字符串需要一次性全部序列化整个对象不同，hash可以对用户结构中的每个字段单独存储，这样当我们需要获取用户信息时可以进行部分获取。

### 1.redis字典的基本操作

- hset key field value #给字典key加入field-value键值对,若field已存在，则更新field对应的value
- hget key field #获取字典key中field对应的value值
- hgetall key #获取字典中所有键值对
- hlen key #获取字典的元素数
- hmset key field value [field value …] #批量创建

![在这里插入图片描述](image/20210530214522935.png)

若是value为数值，也可以进行计数

> hincrby key field increment #字典key中field对应的数值value增加increment

![在这里插入图片描述](image/20210530215112140.png)

### 2.redis字典的内部实现

  字典是redis服务器中出现最频繁的复合型数据结构，除了hash结构的数据会用到字典外，整个redis数据库的所有key和value也组成了一个全局字典，还有待过期时间的key集合也是一个字典。zset集合中存储value和score值的映射关系也是字典结构。

```java
struct RedisDb {
	dict* dict;			//全局字典
	dict* expires;		//过期字典
	...
}
struct zset {
	dict *dict;			//存放value和score的映射关系
	zskiplist *zsl;
}
```

 既然字典在redis中这么重要，那么搞懂它的内部实现就尤为重要。

  字典结构内部包含两个hashtable，通常情况下只有一个hashtable是有值的，但是在字典扩容缩容时，需要分配新的hashtable，然后进行渐进式搬迁，这时候两个hashtable存储的分别是旧的hashtable和新的hashtable。ht[0]为旧的hashtable，ht[1]为新的hashtable。等到搬迁结束之后，旧的hashtable被删除，新的hashtable取而代之。![在这里插入图片描述](image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU1OTk1MA==,size_16,color_FFFFFF,t_70.png)

```c
struct dict {
	...
	dictht ht[2];
}
```

hashtable的结构和Java的HashMap几乎是一样的，都是通过分桶的方式解决hash冲突。第一维是数组，第二维是[链表](https://so.csdn.net/so/search?q=链表&spm=1001.2101.3001.7020)，数组中存储的是第二维链表的第一个元素的指针，如图所示。

![在这里插入图片描述](image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU1OTk1MA==,size_16,color_FFFFFF,t_70-20220411160807219.png)

```c
struct dictEntry {
	void* key;
	void* val;
	dictEntry* next;
}
struct dictht {
	dictEntry** table;
	long size;			//第一维数组的长度
	long used;			//hash表中的元素个数
	...
}
```

### 3.渐进式rehash

  redis的hash相较于Java的HashMap来说还有一点不同就是rehash方式不同，为渐进式rehash，那么为什么要采用这种方式呢？
 因为，大字典的扩容时比较耗时的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的redis很难承受这样耗时的过程，因而redis使用渐进式rehash，虽然会慢一些，但是最终肯定是可以搬迁完的。

```c
dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing){
	long index;
	dictEntry *entry;
	dictht *ht;
	
	//这里进行小步搬迁
	if(dictIsRehashing(d))
		_dictRehashStep(d);
	
	/*获取新元素的索引，如果该元素已经存在了，则索引为-1
	 *如果新元素已经存在，则返回空指针 */
	if(
	(index = _dictKeyIndex(d, key, dictHashKey(d, key), existing)) 
	== -1)
		return NUll;
	
	/*分配内存并存储新的entry
	 *将元素插入尾部
	 *系统优先访问最近添加的entry */
	//如果字典处于搬迁过程中，要将新的元素挂接到新的数组下面
	ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];
	entry = zmalloc(sizeof(*entry));
	entry->next = ht->table[index];
	ht->table[index] = entry;
	ht->used++;
	
	/*设置字典输入字段 */
	dictSetKey(d, entry, key);
	return entry;
}
```

 字典搬迁在当前字典的后续指令中，比如来自客户端的hset、hdel等命令之后，这样稍显被动了些，除此之外，redis还会在定时任务中对字典进行主动搬迁。

```c
//服务器定时任务
void databaseCron() {
	...
	if(server.activerehashing) {
		for(j = 0; j < dbs_per_call; j++) {
			int word_done = incrementallyRehash(rehash_db);
			if(work_done) {
				/*如果函数做了一些工作，请到此为止，
				 *将在下一个cron循环中做更多的工作*/
				 break;
			} else {
				/*如果这个db不需要rehash，
				 *将尝试rehash下一个
				 rehash_db++;
				 rehash_db %= server.dbnum;
			}
		}
	}
}
```

### 4.字典的查找过程

  要想对字典进行插入，修改，删除操作都必须先要查找到元素，才可以进行数据结构的修改。因而，搞清楚hash的查找过程是很有必要的。
  hashtable的元素是在第二维的链表上，所以首先要做的是确定目标key处在哪个链表上,然后再顺序遍历这个链表找到目标key。

```c
func get(key) {
	//hash函数计算得出目标元素在数组中的位置，也就是处于哪个链表上
	let index = hash_func(key) % size;
	let entry = table[index];
	//遍历链表，找目标key
	while(entry != NULL){
		//查找成功，返回目标元素
		if(entry.key == target){
			return entry.value;
		}
		entry = entry.next;
	}
}
```

### **5.扩容和缩容**

#### (1)扩容条件

```c
//如果需要，对hash表进行扩容
static int _dictExpandIfNeeded(dict *d) {
	//若是字典正在进行rehash，则返回，此时选择不扩容
	if(dictIsRehashing(d))
		return DICT_OK;
		
	//若是hash表是空的，将其扩容至初始大小
	if(d->ht[0].size == 0)
		return dictExpand(d, DICT_HT_INITIAL_SIZE);
		
	/*如果元素数量大于等于桶的数量，
	 *且至少满足以下条件之一:
	 *1.该字典是可以进行扩容的
	 *2.元素数量/桶数量的比值大于安全阈值，默认为5
	 *此时要进行扩容，扩容为此时元素数量的两倍大小
	*/
	 if(d->ht[0].used >= d->ht[0].size &&
	 	(dict_can_resize || d->ht[0].used/d->ht[0].size > dict_force_resize_ratio)){
	 		return dictExpand(d, d->ht[0].used*2);
	 	}
	 return DICT_OK;
}
```

#### (2)缩容条件

  当hash表因为元素逐渐被删除变得越来越稀疏时，redis会对hash表进行缩容来减少hash表的第一维数组空间占用。缩容的条件是元素个数低于数组长度的10%，缩容不会考虑字典是否正在rehash，也就是说，字典在进行渐进式rehash时可以缩容。
 为什么缩容时不考虑是否正在rehash呢？个人认为是本来就要将原hashtable中的元素全部迁移至新的hashtable中，最后将旧的hashtable删除，内存释放。此时如果进行缩容的话，对于后面继续rehash以及最后的释放内存并不影响，甚至会更方便这些操作，相当于将一个气球中的气逐渐放了，而不是一次性给它扎破。

```c
int htNeedsResize(dict *dict) {
	long long size, used;
	size = dictSlots(dict);
	used = dictSize(dict);
	return (size > DICT_HT_INITIAL_SIZE &&
			(used*100/size < HASHTABLE_MIN_FILL));
}
```

### 6.深入字典的遍历过程

  Redis对象树的主干是一个字典，如果对象很多的话，主干字典也会非常大。当使用keys命令搜寻指定模式的key时，它会遍历整个主干字典，在遍历的过程中，如果满足匹配条件的key被找到了，还需要判断key指向的对象是否已经过期，若是过期了就需要从主干字典中将该key删除。

迭代器

```c
void keysCommand(client *c){
	dictIterator *di;		//迭代器
	dictEntry *de;			//迭代器当前的entry
	sds pattern = c->argv[1]->ptr;		//keys的匹配模式参数
	int plen = sdslen(pattern);
	int allkeys;		//是否要获取所有key
	unsigned long numkeys = 0;
	void *replylen = addDeferredMultiBulkLength(c);
	
	di = dictGetSafeIterator(c->db->dict);
	allkeys = (pattern[0] == '*' && pattern[1] == '\0');
	while((de = dictNext(di)) != NULL){
		sds key = dictGetKey(de);
		robj *keyobj;
		if(allkeys || stringmatchlen(pattern, plen, key, sdslen(key), 0)){
			keyobj = createStringObject(key, sdslen(key));
			//判断是否过期，过期了要删除元素
			if(expireIfNeeded(c->db, keyobj) == 0){
				addReplyBulk(c, keyobj);
				numkeys++;
			}
			decrRefCount(keyobj);
		}
	}
	dictReleaseIterator(di);
	setDeferredMultiBulkLength(c, replylen, numkeys);
}
```

 前面提到过，字典在扩容时要进行渐进式迁移，同时存在新旧两个hashtable。遍历需要对这两个hashtable依次进行，先遍历完旧的hashtable，再继续遍历新的hashtable。如果在遍历的过程中进行了rehashStep，将已经遍历过的旧的hashtable的元素迁移到了新的hashtable中，这时就存在一个问题，遍历是不是会出现元素的重复。

  Redis为字典的遍历提供了两种迭代器，一种是安全迭代器，一种是不安全迭代器。

```c
typedef struct dictIterator{
	dict *d;		//目标字典对象
	long index;		//当前遍历的槽位置，初始化为-1
	int table;		//ht[0]或ht[1]
	int safe;		//表示迭代器是否安全
	dictEntry *entry;	//迭代器当前指向的对象
	dictEntry *nextEntry;	//迭代器下一个指向的对象
	long long fingerprint;	//迭代器指纹，放置迭代过程中字典被修改
}dictIterator;

//获取非安全迭代器，只读迭代器，允许rehashStep
dictIterator *dictGetIterator(dict *d){
	dictIterator *iter = zmalloc(sizeof(*iter));
	
	iter->d = d;
	iter->table = 0;
	iter->index = -1;
	iter->safe = 0;
	iter->entry = NULL;
	iter->nextEntry = NULL;
	return iter;
}

//获取安全迭代器，允许触发过期处理，禁止rehashStep
dictIterator *dictGetSafeIterator(dict *d) {
	dictIterator *i = dictGetIterator(d);
	
	i->safe = 1;
	return i;
}
```

安全的迭代器可以在遍历过程中对字典进行查找和修改，由于查找和修改会触发过期判断，会删除内部元素。为了保证元素不重复，会禁止rehashStep。
  安全迭代器在刚开始遍历时，会给字典打上一个标记，有了这个标记之后，rehashStep就不会执行，遍历时就不会出现元素重复。

```
typedef struct dict{
	dictType *type;
	void *privdata;
	dictht ht[2];
	long rehashindex;	//标记，表示当前加在字典上的安全迭代器的数量
	unsigned long iterators;
}dict;

//如果存在安全的迭代器，就禁止rehash
static void _dictRehashStep(dict *d){
	if(d->iterators == 0)
		dictRehash(d, l);
}
```

不安全的迭代器是指，在遍历过程中，字典是只读的，不可以修改，只能调用dictNext对字典进行持续遍历，不得调用任何可能触发过期判断的函数。这样不影响rehash，但是遍历的元素可能会重复。

  如果遍历过程中不允许出现重复，或者遍历过程中需要处理元素过期，需要对字典进行修改，那就使用安全迭代器。
  其他情况下，允许出现个别元素重复，一般都使用非安全迭代器。

迭代过程

```c
dictEntry *dictNext(dictIterator *iter){
	while(1){
		if(iter->entry == NULL){
			//遍历一个新槽位下面的链表，数组的index往前移动了
			dictht *ht = &iter->d->ht[iter->table];
			if(iter->index == -1 && iter->table == 0){
				//第一次遍历，刚刚进入遍历过程
				//就是ht[0]数组的第一个元素下面的链表
				if(iter->safe){
					//给字典打安全标记，禁止字典进行rehash
					iter->d->iterators++;
				}else{
					//记录迭代器指纹
					//如果遍历过程中字典有任何变动,指纹就会改变
					iter->fingerprint = dictFingerprint(iter->d);
				}
			}
			iter->index++;
			if(iter->index >= (long)ht->size){
				//最后一个槽位都遍历完了
				if(dictIsRehashing(iter->d) && iter->table == 0){
					//如果处于rehash中，那就继续遍历第二个hashtable
					iter->table++;
					iter->index = 0;
					ht = &iter->d->ht[1];
				}else{
					//结束遍历
					break;
				}
			}
			//将当前遍历的元素记录到迭代器中
			iter->entry = ht->table[iter->index];
		}else{
			//直接将下一个元素记录为本次迭代的元素
			iter->entry = iter->nextEntry;
		}
		if(iter->entry){
			//将下一个元素也记录到迭代器中
			//防止安全迭代过程中当前元素被过期删除后，找不到下一个需要遍历的元素
			//如果后面发生了rehash，当前遍历的链表打散了
			//旧的链表将被一分为二，打散后重新挂接到新数组的两个槽位下
			//结果就是会导致当前链表上的元素会重复遍历
			//如果rehash的链表是index前面的链表，那么这部分链表也会被重复遍历
			iter->nextEntry = iter->entry->next;
			return iter->entry;
		}
	}
	return NULL;
}

//遍历完成后要释放迭代器，安全迭代器需要去掉字典的禁止rehash的标记
//非安全迭代器还需要检查指纹，如果有变动，服务器就会崩溃
void dictReleaseIterator(dictIterator *iter){
	if(!(iter->index == -1 && iter->table == 0)){
		if(iter->safe)
			iter->d->iterators--;	//去掉禁止rehash的标记
		else
			assert(iter->fingerprint == dictFingerprint(iter->d));
	}
	zfree(iter);
}

//计算字典的指纹，也就是将字典的关键字按为糅合到一起
//这样只要有任意的结构变动，指纹都会发生变化
//如果只是某个元素的value被修改了，指纹不会发生变动
long long dictFingerprint(dict *d){
	long long integers[6], hash = 0;
	int j;
	
	integers[0] = (long) d->ht[0].table;
	integers[1] = d->ht[0].size;
	integers[2] = d->ht[0].used;
	integers[3] = (long) d->ht[1].table;
	integers[4] = d->ht[1].size;
	integers[5] = d->ht[1].used;
	
	for(j = 0; j < 6; j++){
		hash += integers[j];
		hash = (~hash) + (hash << 21);
		hash = hash ^ (hash >> 24);
		hash = (hash + (hash << 3) + (hash << 8));
		hash = hash ^ (hash >> 14);
		hash = (hash + (hash << 2)) + (hash << 4);
		hash = hash ^ (hash >> 28);
		hash = hash + (hash << 31);
	}
	return hash;
}
```

