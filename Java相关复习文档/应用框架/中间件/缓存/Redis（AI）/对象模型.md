# **SDS （简单动态字符串）**

**SDS（Simple Dynamic String）就是 Redis 自己实现的一种“可增长的字节串缓冲区”**。

它不像 C 的 char* 需要靠扫 \0 才知道长度，也不会因拼接越界；**长度保存在头里，末尾仍带一个兼容 C 的 '\0'**。Redis 的“字符串值”内部就是把真正的字节数据放进 SDS 里。



## **它长什么样（内存长相）**

SDS 在内存里是“**头部（记录长度/容量） + 内容区（buf） + 末尾 ‘\0’**”。

外部拿到的“字符串指针”其实直接指向内容区的开头 buf[0]。

```
        内存低地址  ───────────────────────────────────────────→  高地址
[ sdshdrX 头部                          ][ b u f | ... | buf[len-1] | '\0' ]
                                         ↑
                                         这就是返回给你的 sds 指针（char* 指向 buf[0]）
```

- **头部**里最重要的两个数：

  - len ：当前已用长度（真实字节数，O(1) 取）
  - alloc：为 buf 预留的容量（不含最后那个 '\0'）

  

- **内容区 buf[]**：存放真实字节；允许中间包含 \0（**二进制安全**）

- **兼容 C**：buf[len] 永远放一个 '\0'，所以很多 C API 也能直接用它（但遇到中间 \0 的场景，必须用带长度的 API）



为省头部开销，SDS 的头有 4 个尺寸版本：sdshdr8/16/32/64（能容纳的最大长度不同）。

**类型信息**塞在 buf 前一个字节的 flags 里，Redis 通过 s[-1] 读出类型，再回溯找到头部，O(1) 取 len/alloc。



## **它是怎么“存”和“长”的（操作过程）**

以 “创建 → 追加 → 取长度” 为例：

1. **创建**（放入 "abc"，长度 3）

   - 申请一块内存：[头 | "abc" | '\0']
   - 记 len=3，alloc 至少是 3（通常会多给一点以减少未来扩容）

   

2. **追加**（再追加 "XYZ"，长度 3）

   - 先检查是否放得下：需要 len+add = 3+3 = 6 <= alloc 吗？

   - **不够就扩容**：策略是

     - 目标新长度 < 1MB：容量 **翻倍**（摊还 O(1)）
     - 否则：按 **+1MB** 线性加

     

   - 可能发生 realloc（内存搬家，**旧指针会失效**）

   - 复制数据到新位置，len=6，buf[6]='\0'

   

3. **取长度**

   - 直接读头里的 len，**O(1)**，不再像 C 字符串那样从头扫到 \0

   

> 小结：**SDS 把“长度/容量”显式存起来**，所有追加/拷贝都先看容量再决定是否扩容，避免溢出；末尾保留一个 '\0' 兼容 C 世界。



## **为什么说“二进制安全”**

- 真实长度在 len，**与是否存在中间 \0 无关**；可以安全存放任意字节序列（图片、压缩块、协议帧…）。
- 末尾那个 '\0' 只是为了让需要 C 字符串的地方（如日志打印）能工作；**不要**靠 strlen() 判断真实长度。





## **SDS 与 Redis “字符串对象”的关系**

Redis 的“字符串类型（String）”是一个 **对象（robj）** 包住具体的编码，**编码为字符串时会用到 SDS**：

- **INT**：能放进 long 的纯数字，直接存在对象里（不需要 SDS）

- **EMBSTR**（小字符串）：

  - “对象头 + SDS + buf”**一次性分配**成一块连续内存，缓存友好、少一次 malloc
  - 一旦需要改动/变长，通常会转成 RAW

  

- **RAW**（普通字符串）：

  - 对象和 SDS 分开分配，方便增长
  - SDS 就是本文的“头+buf+‘\0’”结构

  

> 面试常问：**EMBSTR 和 RAW 区别？**——EMBSTR 适合小且基本不变的字符串；需要增长就转 RAW，以使用 SDS 的动态扩容能力。



## **跟 Java 的对照记忆（你是 Java 背景）**

- **SDS ≈ StringBuilder**：有 length 和 capacity，追加时可能扩容（翻倍/线性 +1MB）
- **buf[len] = '\0'**：相当于为了兼容“老 API”多放了一个结尾标记，但**真实长度**看 len
- **EMBSTR**：有点像“小对象 SSO”，读多改少时更划算；一旦要改，就转“普通堆对象”（RAW+SDS）



## **一屏总结（考官版）**

- **定义**：Redis 的可增长字节串缓冲区，**头部存 len/alloc，末尾有 '\0'**
- **布局**：[sdshdrX | buf... | '\0']，外部指针指向 buf[0]
- **复杂度**：strlen→O(1)，追加摊还 O(1)，扩容可能 realloc（指针会变）
- **特性**：二进制安全；小串用 EMBSTR，一旦修改转 RAW+SDS
- **扩容策略**：<1MB 翻倍，>=1MB 线性 +1MB

# **dict（哈希表）**

- **Redis 内部的通用哈希表实现**，相当于 Java 里的 HashMap。

- 用来存放：

  - Redis 数据库的 **键空间（key -> value 对象）**；
  - 用户的 HASH 类型（field -> value）；
  - 一些内部结构（如 ACL 用户表、模块内部索引）。

  

- 特点：

  - **开放寻址 vs 链地址**：Redis 采用 **链地址法（bucket + 链表）**。
  - **渐进式 rehash**：避免一次性扩容导致阻塞。

  



## **2. 核心结构**

主要有三层：

### **2.1 dict**

```
typedef struct dict {
    dictType *type;       // 类型特定的函数指针集合（hash函数、key dup/free、val dup/free、比较函数）
    void *privdata;       // 私有数据，传给回调函数
    dictht ht[2];         // 两个哈希表，用于渐进式 rehash
    long rehashidx;       // rehash 进度标记（-1 表示不在 rehash）
    unsigned long iterators; // 迭代器安全计数
} dict;
```



### **2.2 dictht（哈希表实例）**

```
typedef struct dictht {
    dictEntry **table;    // 桶数组，每个元素指向一个链表
    unsigned long size;   // 桶数组大小（总容量，2^n）
    unsigned long sizemask; // size-1，用于按位与快速取模
    unsigned long used;   // 已存储的键值对数量
} dictht;
```



### **2.3 dictEntry（节点）**

```
typedef struct dictEntry {
    void *key;
    void *val;            // 联合体，支持指针、u64、s64、double
    struct dictEntry *next; // 链表指针，解决哈希冲突
} dictEntry;
```



## **3. 哈希函数与冲突处理**

- Redis 默认使用 **MurmurHash2**（非加密，但高效、分布好）。
- **冲突处理**：链地址法，把冲突的 dictEntry 串成链表。
- 查找过程：计算 hash → 定位桶（index = hash & sizemask）→ 遍历链表比较 key。



## **4. 扩容与缩容**

- **何时扩容**

  - 条件：used >= size（负载因子 >= 1）
  - 目标：新容量 = 当前已用大小的 **2 倍**（向上取 2^n）

  

- **何时缩容**

  - 条件：used <= size/10
  - 目标：新容量 = 当前已用大小的 **1/2**（向下取 2^n）

  

- **渐进式 rehash**

  - Redis 不会一次性迁移所有元素（会阻塞太久），而是逐步完成：

    1. 分配新表到 ht[1]
    2. rehashidx 从 0 开始，每次迁移一个桶
    3. 在后续的 **增删改查** 操作时，都会顺带迁移一部分桶
    4. 直到 ht[0] 空了，完成 rehash，ht[1] 变成 ht[0]

    

  - 如果没有读写操作，后台也会定时迁移一小部分，保证最终完成。

  



## **5. 渐进式 rehash 的示意**

假设 ht[0] 有 4 个桶，触发扩容后：

```
dict
 ├── ht[0]（旧表，4 桶） rehashidx = 0
 └── ht[1]（新表，8 桶）

操作时：
- 查找：先查 ht[0]，没找到再查 ht[1]
- 插入：直接插入 ht[1]
- 每次操作顺带迁移一个桶（把整个桶的链表挪到 ht[1]）
```

最终所有桶都迁移完成，ht[1] 替换 ht[0]，rehash 结束。



## **6. 迭代器（dictIterator）**

- 支持 **安全迭代器**：禁止在迭代时修改表结构（只能改值）。
- 支持 **不安全迭代器**：可以边迭代边修改，但可能漏/重复元素。



## **7. 性能特点**

- **平均复杂度**：O(1) 增删改查（哈希表 + 链表长度短）

- **最坏复杂度**：O(N)，当哈希冲突严重（链表长）或者一次性 rehash

- **优化点**：

  - 桶数始终保持 2 的幂次，方便快速取模
  - rehash 分步进行，避免阻塞
  - 空闲时会尝试自动迁移（“惰性 + 定时”结合）

  



## **8. 常见面试考点**

1. **为什么要两个 dictht？**

   为了支持渐进式 rehash，旧表和新表共存一段时间。

2. **rehash 时查找怎么做？**

   先查新表，再查旧表；插入直接进新表。

3. **什么时候扩容？什么时候缩容？**

   - used >= size → 扩容
   - used <= size/10 → 缩容

   

4. **rehash 会阻塞吗？**

   不会一次性阻塞，采用渐进式迁移，每次操作顺带迁移一部分桶。

5. **dict 和 hash 类型的关系？**

   Redis 的 hash 类型内部，当 field-value 少且小，会用 **listpack** 存储；超过阈值后就转成 **dict**。



## **9. 和 Java HashMap 对比（便于你记忆）**

- 都是 **数组 + 链表** 结构（Redis 还没用红黑树优化）
- 都支持 **扩容翻倍**，负载因子控制扩容时机
- Redis **渐进式 rehash** 类似 Java8 之后的 **transfer**，但 Redis 的是分布到后续操作中完成，避免阻塞主线程



好的，我们来深入讲解 Redis 的 **listpack** 和 **quicklist** ——这是 Redis 内部实现 **List**、**Hash**、**ZSet** 等结构时非常核心的底层存储单元。



我分成三部分来讲：**listpack（轻量顺序容器） → quicklist（List 的真正实现） → 两者关系与演进**。



------





# **listpack（已淘汰）**

### **1.1 背景**

- Redis 早期用 **ziplist** 实现小型集合（list/hash/zset）。

- 缺陷：

  - 采用**反向指针**（prevlen），删除/扩容时可能引发 **连锁更新**，性能最坏 O(N)。
  - 内部编码混乱，容易触发 bug（Redis 4.x 出过 ziplist 越界漏洞）。

  

- Redis 5.0 引入 **listpack**，作为 ziplist 的替代。



### **1.2 内存布局**

```
[ total_bytes | num_elements | entry1 | entry2 | ... | entryN | 0xFF ]
```

- **total_bytes**：整个 listpack 的字节总长度（方便遍历/扩容）
- **num_elements**：元素个数（entry 数量）
- **entryX**：变长编码的数据单元
- **0xFF**：结束标志



### **1.3 entry 编码**

每个 entry 包括：

- **encoding 字节**：描述这个 entry 的类型（整数 / 字符串）、长度
- **content**：实际内容（整型直接存值，字符串存字节序列）
- **length**：隐式包含在 encoding 里，不需要像 ziplist 用 prevlen



### **1.4 特点**

- **顺序存储**：entry 一个接一个排布

- **无连锁更新**：entry 之间没有 prevlen，删除/更新不影响其他 entry

- **支持整数压缩**：1/2/4/8 字节存储

- **低开销**：比 ziplist 更紧凑、安全、可预测

- **典型用途**：

  - 小型 Hash（field-value 对存进 listpack）
  - 小型 ZSet（member-score 对存进 listpack）
  - quicklist 节点的存储单元

  



# **quicklist（Redis List 的真正实现）**

### **2.1 背景**

- Redis List 早期直接用 **双端链表 linkedlist**（灵活但内存开销大）。
- 后来优化为 **quicklist**（Redis 3.2 引入），兼顾 **内存效率 + 随机访问性能**。



### **2.2 结构**

quicklist 是：

```
双向链表 (quicklistNode)
    └── 每个节点内部存一个压缩块（listpack）
```



### **2.3 quicklistNode**

```
typedef struct quicklistNode {
    struct quicklistNode *prev;
    struct quicklistNode *next;
    unsigned char *zl;     // 指向 listpack
    unsigned int count;    // listpack 内元素个数
    unsigned int sz;       // listpack 字节大小
    ...
} quicklistNode;
```



### **2.4 插入/访问过程**

- 插入：

  - 如果当前节点的 listpack 还没超过阈值（元素个数或字节大小），直接往里写。
  - 如果超过阈值，就新建一个 quicklistNode，把元素放进去。

  

- 访问：

  - 通过双向链表定位到某个节点，再在 listpack 里顺序定位。



### **2.5 特点**

- **内存高效**：listpack 节点比单个 linkedlist 节点占用更紧凑。
- **局部性好**：listpack 内的元素在内存中连续，CPU 缓存友好。
- **灵活**：支持 O(1) 的 LPUSH/RPUSH（头尾插入），也能高效随机遍历。



### **2.6 参数调节**

Redis 提供配置项：

- **list-max-ziplist-size**：控制每个 listpack 的最大元素数或最大字节数（负数代表压缩阈值）。
- **list-compress-depth**：控制链表两端多少节点保持非压缩，中间节点可以 LZF 压缩，进一步省内存。

# **listpack 与 quicklist 的关系与演进**

1. **早期**

   - List → 双端链表 linkedlist
   - 小 Hash/ZSet → ziplist

   

2. **中期（Redis 3.2 ~ 5.0）**

   - List → quicklist（节点用 ziplist 存数据）
   - Hash/ZSet → ziplist

   

3. **现在（Redis 6.0+，7.x）**

   - List → quicklist（节点改用 **listpack** 存数据）
   - Hash/ZSet → listpack
   - ziplist 完全淘汰

   

## **面试常见考点**

1. **为什么用 quicklist 而不是链表？**

   - 链表节点额外开销大（指针+内存碎片），quicklist 节点里用 listpack 紧凑存储，内存效率更高。

   

2. **为什么用 listpack 替代 ziplist？**

   - 避免连锁更新，提高安全性，压缩率更好。

   

3. **quicklist 的操作复杂度？**

   - LPUSH/RPUSH/LPOP/RPOP → O(1)
   - LINDEX（随机访问） → O(N)，但比链表快（因为节点内是连续数组，CPU cache 友好）。

   

4. **listpack 能存什么？**

   - 字符串或整数，entry 有不同编码；ZSet 的 member/score 就打包进 listpack。

   

5. **为什么 listpack 要有 total_bytes 和 num_elements？**

   - total_bytes 让扩容/收缩快速完成；num_elements 让统计 O(1)，不用遍历。

   

一句话总结：

- **listpack** = 一种紧凑、无连锁更新的顺序容器
- **quicklist** = “双向链表 + listpack 节点”组合，Redis List 的最终实现
- **关系**：quicklist 用 listpack 存数据，取代早期的 ziplist，实现了 **高效、紧凑、可扩展的 List**

# skiplist

## **1. 背景与用途**

- Redis 的 ZSet 需要同时满足

  - **按 member 查找分数**（O(1) 或 O(logN)）
  - **按分数范围/排名取值**（O(logN) + O(k)）

  

- 单一数据结构很难兼顾。Redis 采用 **双结构**：

  - **dict**：快速按 key 查分数（O(1)）
  - **skiplist**：有序存储，支持范围查找、按 rank 定位（O(logN)）

  

- skiplist 就是 ZSet 的“排序容器”。



## **2. skiplist 基础概念**

### **2.1 什么是跳表？**

- 本质是**有序链表的多级索引结构**。

- 每个节点可能有多层“前进指针”（forward），层数随机决定。

- 查找时从最高层开始走，走不动就降一层，直到最低层。

- 时间复杂度：

  - 查找/插入/删除：平均 **O(logN)**，最坏 O(N)
  - 顺序遍历：O(N)（比平衡树更直观）

  

### **2.2 Redis 的 skiplist 节点**

```
typedef struct zskiplistNode {
    sds ele;                     // 成员字符串
    double score;                // 分值
    struct zskiplistNode *backward; // 后退指针（便于反向遍历）
    struct zskiplistLevel {
        struct zskiplistNode *forward; // 前进指针
        unsigned long span;            // 跨度（到 forward 节点的距离）
    } level[];                   // 多层索引数组
} zskiplistNode;
```

- **score**：排序的主要依据
- **ele**：成员值（字符串，二级排序条件）
- **level[]**：随机高度的层级数组，每层有 forward 指针和 span
- **span**：记录到下一节点的“跨度”，用于快速算 rank



### **2.3 skiplist 结构体**

```
typedef struct zskiplist {
    struct zskiplistNode *header, *tail; // 头尾节点
    unsigned long length;                // 节点总数
    int level;                           // 当前最高层数
} zskiplist;
```



## **3. 插入过程（核心逻辑）**

1. **随机层数**：新节点的层数由 randomLevel() 决定（概率分布 ~ 几何分布，p=0.25，平均高度 O(logN)）。
2. **找到插入位置**：从最高层往下查找，记录每一层的前驱节点。
3. **插入节点**：在每层的 forward 链表里更新指针，把新节点插进去。
4. **更新 span**：修正前驱和新节点的跨度，保证 rank 计算正确。
5. **更新 backward**：用于反向遍历。



## **4. 查找过程**

- **按分数查**：从最高层开始比较 score，遇到更大分数就降层，直到找到等于目标的节点。
- **按 rank 查**：利用 span 叠加，计算走过的节点数，直到 rank 对应位置。
- **按范围查**：找到 range 的起点节点，再顺链表向前/向后遍历。



## **5. 删除过程**

1. 与插入类似，先找到每层的前驱节点。
2. 更新 forward 指针，跨过待删节点。
3. 修正 span、backward，更新 skiplist 的 tail/level/length。



## **6. 复杂度分析**

- **插入**：O(logN)
- **删除**：O(logN)
- **按 score 查找**：O(logN)
- **按 rank 定位**：O(logN)
- **范围遍历**：O(logN + k) （k 是结果数量）



## **7. Redis skiplist 的特点**

1. **随机层数**：避免维护复杂的平衡树旋转，概率保证性能。

2. **span 跨度**：支持 rank（第几个元素）的快速定位，这是普通跳表没有的优化。

3. **双向链表**：通过 backward 实现从尾部或反向遍历。

4. **和 dict 结合**：

   - dict：member -> score 映射，O(1) 查找
   - skiplist：按 score 排序，支持范围/排名
   - 两者结合，既能快速按 key 查，也能高效按顺序取。

   



## 8. 面试常见问法

1. **为什么 Redis 用 skiplist 而不用平衡树（如 AVL、红黑树）？**

   - 实现简单：不需要旋转维护平衡。
   - 性能稳定：概率保证 O(logN)。
   - 范围查询友好：链表顺序天然支持 range scan。
   - 内存占用可控：平均高度 ~ logN。

   

2. **skiplist 节点为什么要有 span？**

   - 用于 rank 查询，能在 O(logN) 内算出“第 k 个元素”。

   

3. **skiplist 在 ZSet 中怎么用？**

   - 插入/删除元素时同时更新 dict 和 skiplist。
   - 查 member 的 score 用 dict，做排序/范围/排名用 skiplist。

   

4. **skiplist 的层高是怎么分布的？**

   - 默认最大 32 层，每次上升概率 1/4。
   - 平均节点高度 1.33，最高层约 log4(N)。

   





## **9. 直观图示（简化版）**

假设有分数顺序 [1, 4, 7, 9]，skiplist 可能长这样：

```
Level3:   1 ────────────────> 9
Level2:   1 ─────> 4 ─────> 9
Level1:   1 -> 4 -> 7 -> 9
```

查找分数 7：

- 从 level3 开始，1 -> 9（太大，退层）
- 从 level2 开始，1 -> 4 -> 9（太大，退层）
- 从 level1 开始，4 -> 7 ✅ 找到



✅ 总结一句话：

**Redis 的 skiplist 是“带 span 的概率平衡多级链表”，和 dict 一起实现了 ZSet。**

它兼顾了按 key 查找的 O(1) 和按分数/排名操作的 O(logN)，同时范围查询顺序遍历性能极好。



# HyperLogLog

## **1. 背景：基数统计问题**

- 问题：统计集合中有多少 **不重复的元素**。
- 精确做法：用 Set 存储所有元素 → 内存占用 O(n)，大数据时不现实。
- 近似做法：利用概率特征压缩存储，只存“统计特征”，不用存具体元素。





## **2. 核心原理**

HyperLogLog 的算法来自 Flajolet 等人的论文 (2007)。主要步骤：





### **(1) 哈希映射**

- 把每个输入元素用一个哈希函数（如 MurmurHash）映射为一个二进制串（足够长，比如 64bit）。
- 哈希保证“元素分布随机”。





### **(2) 分桶（registers）**

- 将哈希值的高位用于确定落在哪个桶（register）。Redis 默认 16384 个桶（2^14）。
- 每个桶保存一个整数，表示“这个桶里见过的最长前导零数”。





### **(3) 前导零**

- 哈希值的剩余部分（低位）用于计算**前导零的个数**。
- 例如哈希值 000100101... → 前导零数 = 3。
- 意义：前导零越长，越罕见 → 说明集合可能越大。







### **(4) 更新桶**

- 每次元素进来，更新对应桶的值为 max(原值, 当前前导零数)。
- 所以每个桶只需存一个小整数（Redis 用 6bit 存一个桶）。







### **(5) 基数估计**

- 最后，HyperLogLog 会把所有桶的值取出，用 **调和平均数 + 校正公式** 得到一个全局基数估计值。

- 直觉：

  

  - 很多桶值都小 → 集合小；
  - 出现大前导零数 → 集合大。

  





## **3. 内部结构**

- Redis 用 16384 个桶，每个桶用 6 位存储 → 总共 16384 × 6 bit ≈ 12 KB。
- 固定 12KB，无论加多少元素，内存不会增长。





## **4. 精度 & 误差**

- 理论标准误差：1.04 / sqrt(m)，其中 m=桶数=16384。
- 所以误差 ≈ 0.81%。
- 大集合（百万/千万/亿级）时依然稳定。
- 小集合时会偏差较大，Redis 内部做了 **线性计数修正**（Linear Counting）来改善。





## **5. 特点总结**

- **优点**：

  - 固定小内存（12KB）即可统计海量数据。
  - 支持合并（PFMERGE），适合分布式/分片统计。

  

- **缺点**：

  - 有误差（±1%），不能当作精确计数。
  - 只能统计基数，不能查具体元素。

  



## **6. 小例子**

假设统计网页独立访客：

```
PFADD uv:2025-09-04 user1
PFADD uv:2025-09-04 user2
PFADD uv:2025-09-04 user1   # 重复访问，内部哈希冲掉了
PFCOUNT uv:2025-09-04       # 返回 2 （近似值）
```



✅ **一句话总结**：

Redis HyperLogLog = “**用 16384 个桶记录哈希前导零分布 → 用概率公式估算集合基数**”。它用 **12KB 空间**换来了**近似去重计数能力**，在 UV 统计、活跃用户量级估算里非常常用。





# **Bitmap**

## **1. 它是什么**

- Redis 把一个 **字符串（String）** 看作一组位（bit），可随机访问和修改其中的每一位。
- 用 Bitmap 就能把 **用户 ID → bit 偏移** 映射，用 0/1 来表示某个状态。





## **2. 它提供的功能**

- **精确记录二值状态**，典型应用：

  - 用户签到：第 n 位 = 用户 n 是否签到
  - 是否登录过：第 n 位 = 用户 n 是否登录
  - 在线/离线状态统计

  

- 能够高效存储：1 亿用户只需要约 12MB 空间（1 位/用户）。





## **3. 常用语法**

```
# 设置某一位
SETBIT key offset value
例子: SETBIT sign:2025-09-04 1001 1   # 用户1001签到

# 获取某一位
GETBIT key offset
例子: GETBIT sign:2025-09-04 1001     # 查询用户1001是否签到

# 统计置 1 的位个数
BITCOUNT key [start end]
例子: BITCOUNT sign:2025-09-04        # 统计当天签到人数

# 多个 Bitmap 做逻辑运算（与/或/异或/非）
BITOP AND destkey key1 key2 ...
BITOP OR  destkey key1 key2 ...
例子: BITOP OR week_sign sign:2025-09-01 sign:2025-09-02 ... sign:2025-09-07
```

